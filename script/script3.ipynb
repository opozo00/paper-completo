{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "from pyannote.core import Annotation, Segment\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directorio actual\n",
    "current_directory = os.path.dirname(os.path.abspath('script3.ipynb'))\n",
    "# directorio hacia arriba desde el directorio actual\n",
    "server_directory = os.path.abspath(os.path.join(current_directory, \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir la ruta del directorio 'server' con los subdirectorios y el nombre del archivo\n",
    "audio = os.path.join(server_directory, \"server\", \"merge\", \"output_1711654624249.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#output_1712601082673 -> solo\n",
    "#output_1712601003765 -> solo\n",
    "#output_1712600490787 -> solo\n",
    "#output_1712600294096 -> solo \n",
    "#prueba -> con lohana\n",
    "#output_1711654624249 -> con kattia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "der = DiarizationErrorRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=os.environ['HUGGIN_FACE_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send pipeline to GPU (when available)\n",
    "pipeline.to(torch.device(\"cuda\"))\n",
    "diarization = pipeline(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultDiarization():\n",
    "    #diccionario = {}    \n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        inicio,fin =turn.start,turn.end\n",
    "        #return inicio,fin\n",
    "        print(f\"start={turn.start:.3f}s stop={turn.end:.3f}s speaker_{speaker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=0.008s stop=0.416s speaker_SPEAKER_00\n",
      "start=2.216s stop=2.997s speaker_SPEAKER_01\n",
      "start=3.930s stop=6.290s speaker_SPEAKER_01\n",
      "start=4.559s stop=6.528s speaker_SPEAKER_00\n",
      "start=7.988s stop=10.059s speaker_SPEAKER_00\n",
      "start=10.688s stop=12.623s speaker_SPEAKER_00\n",
      "start=13.268s stop=13.846s speaker_SPEAKER_01\n",
      "start=14.372s stop=15.170s speaker_SPEAKER_01\n",
      "start=15.543s stop=16.817s speaker_SPEAKER_01\n",
      "start=17.105s stop=18.175s speaker_SPEAKER_00\n",
      "start=18.379s stop=19.601s speaker_SPEAKER_01\n",
      "start=20.823s stop=22.250s speaker_SPEAKER_00\n",
      "start=22.148s stop=22.742s speaker_SPEAKER_01\n",
      "start=25.340s stop=28.769s speaker_SPEAKER_01\n",
      "start=29.024s stop=29.550s speaker_SPEAKER_01\n",
      "start=29.346s stop=30.467s speaker_SPEAKER_00\n",
      "start=30.739s stop=30.908s speaker_SPEAKER_00\n",
      "start=35.475s stop=38.328s speaker_SPEAKER_00\n",
      "start=38.345s stop=38.362s speaker_SPEAKER_00\n",
      "start=38.379s stop=38.854s speaker_SPEAKER_00\n",
      "start=39.160s stop=45.849s speaker_SPEAKER_01\n",
      "start=49.007s stop=49.448s speaker_SPEAKER_00\n",
      "start=50.348s stop=56.630s speaker_SPEAKER_00\n",
      "start=50.823s stop=51.672s speaker_SPEAKER_01\n",
      "start=57.054s stop=57.683s speaker_SPEAKER_01\n",
      "start=57.683s stop=57.767s speaker_SPEAKER_00\n",
      "start=57.767s stop=57.835s speaker_SPEAKER_01\n",
      "start=57.835s stop=57.886s speaker_SPEAKER_00\n",
      "start=57.886s stop=57.954s speaker_SPEAKER_01\n",
      "start=57.954s stop=57.971s speaker_SPEAKER_00\n",
      "start=59.431s stop=60.908s speaker_SPEAKER_00\n",
      "start=60.942s stop=60.993s speaker_SPEAKER_00\n",
      "start=60.993s stop=62.436s speaker_SPEAKER_01\n",
      "start=62.453s stop=62.538s speaker_SPEAKER_01\n",
      "start=63.234s stop=64.796s speaker_SPEAKER_00\n",
      "start=64.915s stop=68.650s speaker_SPEAKER_01\n",
      "start=69.075s stop=70.688s speaker_SPEAKER_01\n"
     ]
    }
   ],
   "source": [
    "resultDiarization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(audio_file):\n",
    "    # Se cargan valores de referencia y de hipótesis para audio_file\n",
    "    reference = Annotation()\n",
    "    reference[Segment(0.056, 1.678)] = 'Speaker1'\n",
    "    reference[Segment(2.315, 4.750)] = 'Speaker2'\n",
    "    reference[Segment(4.752, 12.231)] = 'Speaker1'\n",
    "    reference[Segment(13.411, 19.391)] = 'Speaker2'\n",
    "    reference[Segment(21.566, 22.083)] = 'Speaker2'\n",
    "    reference[Segment(25.403, 29.248)] = 'Speaker2'\n",
    "    reference[Segment(29.478, 30.233)] = 'Speaker1'\n",
    "    reference[Segment(35.588, 37.959)] = 'Speaker1'\n",
    "    reference[Segment(39.491, 45.277)] = 'Speaker2'\n",
    "    reference[Segment(49.058, 51.076)] = 'Speaker1'\n",
    "    reference[Segment(51.381, 56.673)] = 'Speaker1'\n",
    "    reference[Segment(59.507, 60.702)] = 'Speaker1'\n",
    "    reference[Segment(61.077, 61.212)] = 'Speaker2'\n",
    "    reference[Segment(63.320, 64.770)] = 'Speaker1'\n",
    "    reference[Segment(64.958, 70.520)] = 'Speaker2'\n",
    "    #reference[Segment(6, 10.310)] = 'Speaker2'\n",
    "    hypothesis = Annotation()\n",
    "    hypothesis[Segment(0.008, 6.290)] = 'Speaker1'\n",
    "    hypothesis[Segment(2.216, 7.716)] = 'Speaker2'\n",
    "    hypothesis[Segment(4.559, 6.528)] = 'Speaker1'\n",
    "    hypothesis[Segment(7.988, 10.059)] = 'Speaker1'\n",
    "    hypothesis[Segment(10.688, 12.623)] = 'Speaker1'\n",
    "    hypothesis[Segment(13.268, 16.817)] = 'Speaker2'\n",
    "    hypothesis[Segment(17.105, 18.175)] = 'Speaker1'\n",
    "    hypothesis[Segment(18.379, 19.601)] = 'Speaker2'\n",
    "    hypothesis[Segment(20.823, 22.250)] = 'Speaker1'\n",
    "    hypothesis[Segment(22.148, 22.742)] = 'Speaker2'\n",
    "    hypothesis[Segment(25.340, 28.769)] = 'Speaker2'\n",
    "    hypothesis[Segment(29.024, 29.550)] = 'Speaker2'\n",
    "    hypothesis[Segment(29.346, 38.854)] = 'Speaker1'\n",
    "    hypothesis[Segment(39.160, 45.849)] = 'Speaker2'\n",
    "    hypothesis[Segment(49.007, 49.448)] = 'Speaker1'\n",
    "    hypothesis[Segment(50.348, 56.630)] = 'Speaker1'\n",
    "    hypothesis[Segment(50.823, 51.672)] = 'Speaker2'\n",
    "    hypothesis[Segment(57.054, 57.683)] = 'Speaker2'\n",
    "    hypothesis[Segment(57.683, 57.767)] = 'Speaker1'\n",
    "    hypothesis[Segment(57.767, 57.835)] = 'Speaker2'\n",
    "    hypothesis[Segment(57.835, 57.886)] = 'Speaker1'\n",
    "    hypothesis[Segment(57.886, 57.954)] = 'Speaker2'\n",
    "    hypothesis[Segment(57.954, 60.993)] = 'Speaker1'\n",
    "    hypothesis[Segment(60.993, 62.538)] = 'Speaker2'\n",
    "    hypothesis[Segment(63.234, 64.796)] = 'Speaker1'\n",
    "    hypothesis[Segment(64.915, 70.688)] = 'Speaker2'\n",
    "    \n",
    "    return reference, hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DER: 0.596\n"
     ]
    }
   ],
   "source": [
    "# Cargar la verdad de referencia y la hipótesis\n",
    "reference, hypothesis = load_annotations('prueba.wav')\n",
    "# Calcular la tasa de error de diarización\n",
    "error_rate = der(reference, hypothesis)\n",
    "print(\"DER: {0:.3f}\".format(error_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
